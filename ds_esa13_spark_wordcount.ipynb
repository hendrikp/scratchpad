{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DS ESA 13 Spark Basics (Polczynski)\n",
    "-----------------------------------\n",
    "\n",
    "Load the complete Shakespeare writings from here, clean the file (there is some legal text at the beginning and in the file; you can do it by hand if needed) and search for the #24 most used word in his writings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM', 'SHAKESPEARE IS COPYRIGHT 1990-1993 BY WORLD LIBRARY, INC., AND IS', 'PROVIDED BY PROJECT GUTENBERG ETEXT OF ILLINOIS BENEDICTINE COLLEGE', 'WITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE', 'DISTRIBUTED SO LONG AS SUCH COPIES (1) ARE FOR YOUR OR OTHERS', 'PERSONAL USE ONLY, AND (2) ARE NOT DISTRIBUTED OR USED', 'COMMERCIALLY.  PROHIBITED COMMERCIAL DISTRIBUTION INCLUDES BY ANY', 'SERVICE THAT CHARGES FOR DOWNLOAD TIME OR FOR MEMBERSHIP.>>']\n"
     ]
    }
   ],
   "source": [
    "# set up\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from itertools import islice\n",
    "import re\n",
    "\n",
    "# clean up spark context for reuse (when running multiple times in notebook)\n",
    "try:\n",
    "    if sc != None:\n",
    "        sc.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# init vars for first run\n",
    "conf = None\n",
    "sc = None\n",
    "\n",
    "# load up spark context\n",
    "if __name__ == \"__main__\" and sc == None:\n",
    "    conf = SparkConf().setAppName(\"DS ESA13\").setMaster(\"local[*]\")\n",
    "    sc = SparkContext(conf = conf)\n",
    "    \n",
    "# set replacement string to remove unwanted data later\n",
    "removeLicense = \"\"\"<<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM\n",
    "SHAKESPEARE IS COPYRIGHT 1990-1993 BY WORLD LIBRARY, INC., AND IS\n",
    "PROVIDED BY PROJECT GUTENBERG ETEXT OF ILLINOIS BENEDICTINE COLLEGE\n",
    "WITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE\n",
    "DISTRIBUTED SO LONG AS SUCH COPIES (1) ARE FOR YOUR OR OTHERS\n",
    "PERSONAL USE ONLY, AND (2) ARE NOT DISTRIBUTED OR USED\n",
    "COMMERCIALLY.  PROHIBITED COMMERCIAL DISTRIBUTION INCLUDES BY ANY\n",
    "SERVICE THAT CHARGES FOR DOWNLOAD TIME OR FOR MEMBERSHIP.>>\"\"\"\n",
    "\n",
    "removeLicense = removeLicense.split(\"\\n\")\n",
    "print(removeLicense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 24 most used words in the shakespeak dataset:\n",
      "the: 27379\n",
      "and: 26084\n",
      "to: 19771\n",
      "of: 17484\n",
      "you: 13826\n",
      "my: 12489\n",
      "that: 11318\n",
      "in: 11112\n",
      "is: 9319\n",
      "not: 8512\n",
      "with: 7791\n",
      "me: 7777\n",
      "it: 7725\n",
      "for: 7655\n",
      "be: 6897\n",
      "his: 6859\n",
      "he: 6679\n",
      "your: 6657\n",
      "this: 6609\n",
      "but: 6277\n",
      "have: 5902\n",
      "as: 5749\n",
      "thou: 5549\n",
      "him: 5205\n"
     ]
    }
   ],
   "source": [
    "# helper function to skip first n lines\n",
    "def skipLines(data, n):\n",
    "    return data.mapPartitionsWithIndex(lambda i, iter: islice(iter, n, None) if i == 0 else iter)\n",
    "\n",
    "# helper function to filter out lines\n",
    "def removeLines(data, removelines):\n",
    "    return data.filter(lambda line: not any(l in line for l in removelines))\n",
    "\n",
    "# helper function to filter out short words\n",
    "def removeWordsLen(data, n):\n",
    "    return data.filter(lambda word: len(word) > n)\n",
    "\n",
    "# run spark job\n",
    "if sc != None:\n",
    "    lines = sc.textFile(\"ds_esa13_t8.shakespeare.txt\")\n",
    "   \n",
    "    # skip first 246 lines\n",
    "    lines = skipLines(lines, 246)\n",
    "    \n",
    "    # remove inline license\n",
    "    lines = removeLines(lines, removeLicense)\n",
    "\n",
    "    # split words based on space and other special chars such as point and comma etc\n",
    "    # also convert to lowercase\n",
    "    words = lines.flatMap(lambda line: re.split(r'[\\s`\\-=~!@#$%^&*()_+\\[\\]{};\\'\\\\:\"|<,./<>?]', line.lower()))\n",
    "    \n",
    "    # remove short words e.g. I,a and fragments left from special chars\n",
    "    words = removeWordsLen(words, 1)\n",
    "    \n",
    "    # not needed anymore as already removed by excluding short words\n",
    "    # remove empty words result from split\n",
    "    # words = words.filter(bool) # empty string is false...\n",
    "    \n",
    "    # get word counts\n",
    "    wordCounts = words.countByValue()\n",
    "    \n",
    "    # sort by occurence\n",
    "    sortedItemCounters = sc.parallelize(wordCounts.items()).sortBy(lambda wc: wc[1], ascending=False)\n",
    "    \n",
    "    # output all\n",
    "    # print(sortedItemCounters.collect())\n",
    "    \n",
    "    # output first 24\n",
    "    print(\"The 24 most used words in the shakespeak dataset:\")\n",
    "    for word, count in sortedItemCounters.take(24):\n",
    "        print(\"{}: {}\".format(word, count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
